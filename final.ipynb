{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UGV obstacle aviodance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import re\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading txt files (and pad)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwm_left = list()\n",
    "pwm_right = list()\n",
    "srf_right = list()\n",
    "srf_left = list()\n",
    "\n",
    "max_length = 120\n",
    "\n",
    "for FolderName in [name for name in os.listdir(\"./Data robot Modified\") if os.path.isdir(os.path.join(\"./Data robot Modified\", name))]:\n",
    "   path = f'./Data robot Modified/{FolderName}'\n",
    "   for filename in glob.glob(os.path.join(path, 'pwm_left.txt')):\n",
    "      with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "         x = re.findall(r'-?\\d+\\.?\\d*', f.read())\n",
    "         x = [eval(x[i]) for i in range(len(x))] \n",
    "         for i in range(max_length-len(x)):\n",
    "            x.insert(0,0)  # add zero at the begining\n",
    "         pwm_left.append(x)\n",
    "   \n",
    "   for filename in glob.glob(os.path.join(path, 'pwm_right.txt')):\n",
    "      with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "         x = re.findall(r'-?\\d+\\.?\\d*', f.read())\n",
    "         x = [eval(x[i]) for i in range(len(x))] \n",
    "         for i in range(max_length-len(x)):\n",
    "            x.insert(0,0)  # add zero at the begining\n",
    "         pwm_right.append(x)\n",
    "      \n",
    "   for filename in glob.glob(os.path.join(path, 'right_srf.txt')):\n",
    "      with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "         x = re.findall(r'-?\\d+\\.?\\d*', f.read())\n",
    "         x = [eval(x[i]) for i in range(len(x))] \n",
    "         for i in range(max_length-len(x)):\n",
    "            x.insert(0,0)  # add zero at the begining\n",
    "         srf_right.append(x)\n",
    "      \n",
    "   for filename in glob.glob(os.path.join(path, 'left_srf.txt')):\n",
    "      with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "         x = re.findall(r'-?\\d+\\.?\\d*', f.read())\n",
    "         x = [eval(x[i]) for i in range(len(x))] \n",
    "         for i in range(max_length-len(x)):\n",
    "            x.insert(0,0)  # add zero at the begining\n",
    "         srf_left.append(x)\n",
    "      \n",
    "pwm_left = [pwm_left[i][j] for i in range(len(pwm_left)) for j in range(len(pwm_left[i]))]\n",
    "pwm_right = [pwm_right[i][j] for i in range(len(pwm_right)) for j in range(len(pwm_right[i]))]\n",
    "srf_left = [srf_left[i][j] for i in range(len(srf_left)) for j in range(len(srf_left[i]))]\n",
    "srf_right = [srf_right[i][j] for i in range(len(srf_right)) for j in range(len(srf_right[i]))]\n",
    "\n",
    "controller_data = pd.DataFrame({'pwm left': np.array(pwm_left).reshape(-1,),\n",
    "                                 'pwm right': np.array(pwm_right).reshape(-1,),\n",
    "                                 'srf left': np.array(srf_left).reshape(-1,),\n",
    "                                 'srf right': np.array(srf_right).reshape(-1,)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading txt files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwm_left = list()\n",
    "pwm_right = list()\n",
    "srf_right = list()\n",
    "srf_left = list()\n",
    "\n",
    "for FolderName in [name for name in os.listdir(\"./Data robot Modified\") if os.path.isdir(os.path.join(\"./Data robot Modified\", name))]:\n",
    "   path = f'./Data robot Modified/{FolderName}'\n",
    "   for filename in glob.glob(os.path.join(path, 'pwm_left.txt')):\n",
    "      with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "         x = re.findall(r'-?\\d+\\.?\\d*', f.read())\n",
    "         x = [eval(x[i]) for i in range(len(x))] \n",
    "         pwm_left.append(x)\n",
    "   \n",
    "   for filename in glob.glob(os.path.join(path, 'pwm_right.txt')):\n",
    "      with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "         x = re.findall(r'-?\\d+\\.?\\d*', f.read())\n",
    "         x = [eval(x[i]) for i in range(len(x))] \n",
    "         pwm_right.append(x)\n",
    "      \n",
    "   for filename in glob.glob(os.path.join(path, 'right_srf.txt')):\n",
    "      with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "         x = re.findall(r'-?\\d+\\.?\\d*', f.read())\n",
    "         x = [eval(x[i]) for i in range(len(x))] \n",
    "         srf_right.append(x)\n",
    "      \n",
    "   for filename in glob.glob(os.path.join(path, 'left_srf.txt')):\n",
    "      with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "         x = re.findall(r'-?\\d+\\.?\\d*', f.read())\n",
    "         x = [eval(x[i]) for i in range(len(x))] \n",
    "         srf_left.append(x)\n",
    "      \n",
    "pwm_left = [pwm_left[i][j] for i in range(len(pwm_left)) for j in range(len(pwm_left[i]))]\n",
    "pwm_right = [pwm_right[i][j] for i in range(len(pwm_right)) for j in range(len(pwm_right[i]))]\n",
    "srf_left = [srf_left[i][j] for i in range(len(srf_left)) for j in range(len(srf_left[i]))]\n",
    "srf_right = [srf_right[i][j] for i in range(len(srf_right)) for j in range(len(srf_right[i]))]\n",
    "\n",
    "controller_data = pd.DataFrame({'pwm left': np.array(pwm_left).reshape(-1,),\n",
    "                                 'pwm right': np.array(pwm_right).reshape(-1,),\n",
    "                                 'srf left': np.array(srf_left).reshape(-1,),\n",
    "                                 'srf right': np.array(srf_right).reshape(-1,)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed to position function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position(pwm_right, pwm_left):\n",
    "    r = 0.02\n",
    "    L2 = 1\n",
    "    max_speed = 100\n",
    "    Ts = 0.1\n",
    "    heading = 0\n",
    "    w = 0\n",
    "    x = [0]\n",
    "    y = [0]\n",
    "    v_right = np.array([i*max_speed*r/100. for i in pwm_right])\n",
    "    v_left = np.array([i*max_speed*r/100. for i in pwm_left])\n",
    "\n",
    "    v_x = (v_right + v_left)/2\n",
    "    v_y = (v_right + v_left)/2\n",
    "    w = v_left - v_right\n",
    "    w = [i/L2 for i in w]\n",
    "    for i in range(len(v_x)-1):\n",
    "        v_x[i] = v_x[i]*(np.sin(heading))\n",
    "        x.append(v_x[i]*Ts+x[i])\n",
    "        v_y[i] = v_y[i]*(np.cos(heading))\n",
    "        y.append(v_y[i]*Ts+y[i])\n",
    "        heading = w[i]*Ts+heading\n",
    "\n",
    "    plt.plot(x[0],y[0],'r*')\n",
    "    plt.plot(x[1:],y[1:])\n",
    "    plt.plot(x[len(x)-1],y[len(x)-1],'g*')\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**proposed paths for training (with pad)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_x = list()\n",
    "pos_y = list()\n",
    "\n",
    "plt.title(\"arc move to left\")\n",
    "x,y = position(pwm_right[:120], pwm_left[:120])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(0.1,1.5,0.1), 0, 2, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"arc move to right\")\n",
    "x,y = position(pwm_right[120:240], pwm_left[120:240])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(-0.1,-1.5,-0.1), 0, 2, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Front back\")\n",
    "x,y = position(pwm_right[240:360], pwm_left[240:360])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(1,-1,-0.1), 5, 6, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"mismatched tunnel\")\n",
    "x,y = position(pwm_right[360:480], pwm_left[360:480])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(-0.1,-1.5,-0.1), 0, 2, color='red', alpha=0.7)\n",
    "plt.fill_between(np.arange(5,6,0.1), 1, 3, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"stuck\")\n",
    "x,y = position(pwm_right[480:600], pwm_left[480:600])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(1,-1,-0.1), 3, 3.5, color='red', alpha=0.7)\n",
    "plt.fill_between(np.arange(1,-1,-0.1), -1, -0.5, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"tunnel\")\n",
    "x,y = position(pwm_right[600:720], pwm_left[600:720])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(0.5,1,0.1), -0.1, 9, color='red', alpha=0.7)\n",
    "plt.fill_between(np.arange(-0.5,-1,-0.1), -0.1, 9, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"turnaround right\")\n",
    "x,y = position(pwm_right[720:840], pwm_left[720:840])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(1,-1,-0.1), 4.5, 5, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"turnaround left\")\n",
    "x,y = position(pwm_right[840:], pwm_left[840:])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(1,-1,-0.1), 4.5, 5, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "pos_x = np.array(sum(pos_x, []))\n",
    "pos_y = np.array(sum(pos_y, []))\n",
    "\n",
    "identification_data = pd.DataFrame({'pwm left': np.array(pwm_left).reshape(-1,),\n",
    "                                    'pwm right': np.array(pwm_right).reshape(-1,),\n",
    "                                    'x position': np.array(pos_x).reshape(-1,),\n",
    "                                    'y position': np.array(pos_y).reshape(-1,)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**proposed paths for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_x = list()\n",
    "pos_y = list()\n",
    "\n",
    "plt.title(\"arc move to left\")\n",
    "x,y = position(pwm_right[:39], pwm_left[:39])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(0.1,1.5,0.1), 0, 2, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"arc move to right\")\n",
    "x,y = position(pwm_right[39:78], pwm_left[39:78])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(-0.1,-1.5,-0.1), 0, 2, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Front back\")\n",
    "x,y = position(pwm_right[78:197], pwm_left[78:197])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(1,-1,-0.1), 5, 6, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"mismatched tunnel\")\n",
    "x,y = position(pwm_right[197:286], pwm_left[197:286])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(-0.1,-1.5,-0.1), 0, 2, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"stuck\")\n",
    "x,y = position(pwm_right[286:381], pwm_left[286:381])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(1,-1,-0.1), 3, 3.5, color='red', alpha=0.7)\n",
    "plt.fill_between(np.arange(1,-1,-0.1), -1, -0.5, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"tunnel\")\n",
    "x,y = position(pwm_right[381:446], pwm_left[381:446])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(0.5,1,0.1), -0.1, 9, color='red', alpha=0.7)\n",
    "plt.fill_between(np.arange(-0.5,-1,-0.1), -0.1, 9, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"turn around\")\n",
    "x,y = position(pwm_right[446:511], pwm_left[446:511])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(1,-1,-0.1), 4.5, 5, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"turn around otherside\")\n",
    "x,y = position(pwm_right[511:], pwm_left[511:])\n",
    "pos_x.append(x)\n",
    "pos_y.append(y)\n",
    "plt.fill_between(np.arange(1,-1,-0.1), 4.5, 5, color='red', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "pos_x = np.array(sum(pos_x, []))\n",
    "pos_y = np.array(sum(pos_y, []))\n",
    "\n",
    "data = pd.DataFrame({'pwm left': np.array(pwm_left).reshape(-1,),\n",
    "                     'pwm right': np.array(pwm_right).reshape(-1,),\n",
    "                     'x position': np.array(pos_x).reshape(-1,),\n",
    "                     'y position': np.array(pos_y).reshape(-1,)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalizer_std(x):\n",
    "    scaler = StandardScaler()\n",
    "    if isinstance(x,pd.Series):\n",
    "        x = scaler.fit_transform(x.values.reshape((-1,1)))\n",
    "    else:\n",
    "        for i in x.columns:\n",
    "            x[i] = scaler.fit_transform(x[i].values.reshape((-1,1)))\n",
    "    return x\n",
    "\n",
    "def feature_normalizer_minmax(x):\n",
    "    scaler = MinMaxScaler()\n",
    "    if isinstance(x,pd.Series):\n",
    "        x = scaler.fit_transform(x.values.reshape((-1,1)))\n",
    "    else:\n",
    "        for i in x.columns:\n",
    "            x[i] = scaler.fit_transform(x[i].values.reshape((-1,1)))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = feature_normalizer_std(data)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowpass(x,dt=1,taw=9):\n",
    "    a = dt/(dt + taw)\n",
    "    y = [0 for i in range(len(x))]\n",
    "    y[0] = x[0]\n",
    "    for i in range(len(x)-1):\n",
    "        y[i+1] = y[i] + a*(x[i+1] - x[i])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disturbance rejection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_dist(x_new,x_old):\n",
    "    if (abs(x_old)>40):\n",
    "        return x_old,x_old\n",
    "    else:\n",
    "        return x_new,x_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifier using KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**preprocessing batches and time series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "\tx, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, -2:]\n",
    "\t\tx.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(x), np.array(y)\n",
    "\n",
    "# define input sequence\n",
    "# convert to [rows, columns] structure\n",
    "\n",
    "in_seq1 = np.array(data[[\"pwm left\"]]).reshape(-1, 1)\n",
    "in_seq2 = np.array(data[[\"pwm right\"]]).reshape(-1, 1)\n",
    "in_seq3 = np.array(data[[\"x position\"]]).reshape(-1, 1)\n",
    "in_seq4 = np.array(data[[\"y position\"]]).reshape(-1, 1)\n",
    "out_seq1 = np.array(data[[\"x position\"]]).reshape(-1, 1)\n",
    "out_seq2 = np.array(data[[\"y position\"]]).reshape(-1, 1)\n",
    "\n",
    "# horizontally stack columns\n",
    "dataset = np.hstack((in_seq1, in_seq2, in_seq3, in_seq4, out_seq1, out_seq2))\n",
    "# convert into input/output (120 time steps as padded in the begining)\n",
    "n_steps = 80\n",
    "x_train_seq, y_train_seq = split_sequences(dataset, n_steps)\n",
    "n_input = x_train_seq.shape[1] * x_train_seq.shape[2]\n",
    "n_output = y_train_seq.shape[1]\n",
    "# for i in range(len(x)):\n",
    "# \tprint(x_train_seq[i], y_train_seq[i])\n",
    "\n",
    "# flatten input\n",
    "x_train_seq = x_train_seq.reshape((x_train_seq.shape[0], n_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Network model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NN = tf.keras.Sequential()\n",
    "model_NN.add(tf.keras.layers.Input(n_input))\n",
    "model_NN.add(tf.keras.layers.Dropout(0.1))\n",
    "model_NN.add(tf.keras.layers.Dense(20,activation='tanh'))\n",
    "model_NN.add(tf.keras.layers.Dropout(0.1))\n",
    "model_NN.add(tf.keras.layers.Dense(n_output))\n",
    "\n",
    "model_NN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_NN.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss='mse', metrics='mae')\n",
    "history = model_NN.fit(x_train_seq,y_train_seq,batch_size=4,validation_split=0.1,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"mae\"],label=\"Train\")\n",
    "plt.plot(history.history[\"val_mae\"],label=\"Validation\")\n",
    "plt.title(\"MAE\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"],label=\"Train\")\n",
    "plt.plot(history.history[\"val_loss\"],label=\"Validation\")\n",
    "plt.title(\"Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation and Test using a proposed map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwm_right1 = np.arange(70,50,-1)\n",
    "pwm_left1 = np.arange(50,30,-1)\n",
    "# pwm_right2 = np.arange(30,40,1)\n",
    "# pwm_left2 = np.arange(50,40,-1)\n",
    "# pwm_right = np.concatenate((pwm_right1,pwm_right2),axis=0)\n",
    "# pwm_left = np.concatenate((pwm_left1,pwm_left2),axis=0)\n",
    "# pwm_right = np.ones((50,))*70\n",
    "# pwm_left = np.ones((50,))*70\n",
    "pwm_left = np.pad(pwm_right1, (80,0), 'constant', constant_values=(0,))\n",
    "pwm_right = np.pad(pwm_left1, (80,0), 'constant', constant_values=(0,))\n",
    "x,y= position(pwm_right, pwm_left)\n",
    "\n",
    "test_data = pd.DataFrame({'pwm_left': np.array(pwm_left).reshape(-1,),\n",
    "                          'pwm_right': np.array(pwm_right).reshape(-1,),\n",
    "                          'x position': np.array(x).reshape(-1,),\n",
    "                          'y position': np.array(y).reshape(-1,)})\n",
    "\n",
    "test_data = feature_normalizer_std(test_data)\n",
    "\n",
    "in_seq1 = np.array(test_data[[\"pwm_left\"]]).reshape(-1, 1)\n",
    "in_seq2 = np.array(test_data[[\"pwm_right\"]]).reshape(-1, 1)\n",
    "in_seq3 = np.array(test_data[[\"x position\"]]).reshape(-1, 1)\n",
    "in_seq4 = np.array(test_data[[\"y position\"]]).reshape(-1, 1)\n",
    "out_seq1 = np.array(test_data[[\"x position\"]]).reshape(-1, 1)\n",
    "out_seq2 = np.array(test_data[[\"y position\"]]).reshape(-1, 1)\n",
    "\n",
    "dataset = np.hstack((in_seq1, in_seq2, in_seq4, in_seq4, out_seq1, out_seq2))\n",
    "x_test, y_test = split_sequences(dataset, n_steps)\n",
    "n_input = x_test.shape[1] * x_test.shape[2]\n",
    "\n",
    "x_test = x_test.reshape((x_test.shape[0], n_input))\n",
    "prediction = model_NN.predict(x_test)\n",
    "plt.plot(prediction[0,0],prediction[0,1],'r+')\n",
    "plt.plot(prediction[:,0],prediction[:,1])\n",
    "plt.plot(prediction[-1:,0],prediction[-1:,1],'g+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controller using KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**modifing dataset for LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_set = pd.DataFrame({\n",
    "    \"pwm left\": [0.0],\n",
    "    \"pwm right\": [0.0],\n",
    "    \"srf left\": [0.0],\n",
    "    \"srf right\": [0.0]},)\n",
    "\n",
    "LSTM_set = LSTM_set.append(controller_data)\n",
    "LSTM_set[['srf left','srf right']] = LSTM_set[['srf left','srf right']].shift(-1)\n",
    "LSTM_set = LSTM_set.dropna(axis=0)\n",
    "LSTM_set.head(85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put inputs into a single list\n",
    "LSTM_set['single_input_vector'] = LSTM_set[['srf left','srf right','pwm left','pwm right']].apply(tuple, axis=1).apply(list)\n",
    "# Double-encapsulate list so we can sum it in the next step and keep time steps as separate elements\n",
    "LSTM_set['single_input_vector'] = LSTM_set.single_input_vector.apply(lambda x: [list(x)])\n",
    "# Using .cumsum() to include previous row vectors in the current row list of vectors (creating time series)\n",
    "LSTM_set['cumulative_input_vectors'] = LSTM_set.single_input_vector.cumsum()\n",
    "\n",
    "LSTM_set['output_vector'] = LSTM_set[['pwm left','pwm right']].apply(tuple, axis=1).apply(list)\n",
    "\n",
    "LSTM_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = LSTM_set.cumulative_input_vectors.apply(len).max()\n",
    "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(LSTM_set.cumulative_input_vectors.tolist(), max_sequence_length).tolist()\n",
    "LSTM_set['padded_input_vectors'] = pd.Series(padded_sequences).apply(np.asarray)\n",
    "\n",
    "LSTM_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_init = np.asarray(LSTM_set.padded_input_vectors)\n",
    "\n",
    "# Use hstack to and reshape to make the inputs a 3d vector\n",
    "X_train = np.hstack(X_train_init).reshape(len(LSTM_set),max_sequence_length,4)\n",
    "y_train = np.hstack(np.asarray(LSTM_set.output_vector)).reshape(len(LSTM_set),2)\n",
    "\n",
    "print(X_train_init.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input length is the length for one input sequence (i.e. the number of rows for your sample)\n",
    "# Input dim is the number of dimensions in one input vector (i.e. number of input columns)\n",
    "# Output dimensions is the shape of a single output vector\n",
    "input_length = X_train.shape[1]\n",
    "input_dim = X_train.shape[2]\n",
    "output_dim = len(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_control = tf.keras.Sequential()\n",
    "model_control.add(tf.keras.layers.LSTM(100, input_dim = input_dim, input_length = input_length))\n",
    "model_control.add(tf.keras.layers.Dense(output_dim))\n",
    "model_control.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_control.compile(loss='mse',optimizer='sgd', metrics=['mae'])\n",
    "history = model_control.fit(X_train, y_train, validation_split=0.1, batch_size=16, epochs=4, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history[\"mae\"],label=\"Train\")\n",
    "plt.plot(history.history[\"val_mae\"],label=\"Validation\")\n",
    "plt.title(\"mae\")\n",
    "plt.ylabel(\"mae\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"],label=\"Train\")\n",
    "plt.plot(history.history[\"val_loss\"],label=\"Validation\")\n",
    "plt.title(\"Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifier using equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_identifier_train(u, x, eta1=0.5, eta2=0.5, p1=0.5, p2=0.5, Ts=0.001):\n",
    "    '''given u and x are column vectors'''\n",
    "    w_hat = np.random.random((1,10))\n",
    "    w_hat_last = np.zeros(w_hat.shape)\n",
    "    v_hat = np.random.random((10,2))\n",
    "    v_hat_last = np.zeros(v_hat.shape)\n",
    "    # x_hat = np.zeros(x[:,0].reshape(-1,1).shape)\n",
    "    x_hat = x[:,0].reshape(-1,1)\n",
    "    x_hat_last = np.zeros(x_hat.shape)\n",
    "    x_bar = np.concatenate((x[:,0],u[:,0]),axis=0).reshape(-1,1)\n",
    "    # x_bar_hat = np.zeros(x_bar.shape)\n",
    "    x_bar_hat = np.concatenate((x_hat[:,0],u[:,0]),axis=0).reshape(-1,1)\n",
    "\n",
    "    x_bar_hat_last = np.zeros(x_bar_hat.shape)\n",
    "\n",
    "    for i in range(x.shape[1]):\n",
    "        x_bar = np.concatenate((x[:,i],u[:,i]),axis=0).reshape(-1,1)\n",
    "        x_tild = x[:,i].reshape(-1,1) - x_hat\n",
    "        A = -np.eye(1)\n",
    "\n",
    "        w_hat = (-eta1*\n",
    "                    np.matmul(\n",
    "                        (np.matmul(x_tild.T,np.linalg.inv(A))).T \n",
    "                            , (sigmoid(np.matmul(v_hat,x_bar_hat_last))).T ) \n",
    "                                - p1*np.linalg.norm(x_tild,2)*w_hat_last)*Ts +  w_hat_last\n",
    "        \n",
    "        v_hat = (np.matmul(-eta2*\n",
    "                            (np.matmul(\n",
    "                                np.matmul(\n",
    "                                    np.matmul(x_tild.T,np.linalg.inv(A)),w_hat)\n",
    "                                        ,(np.eye(10) - landa(np.matmul(v_hat_last,x_bar_hat_last))))).T,x_bar_hat_last.T) - p2*np.linalg.norm(x_tild,2)*v_hat_last)*Ts + v_hat_last\n",
    "        \n",
    "        x_hat = (np.matmul(A,x_hat_last) \n",
    "                    + np.matmul(w_hat,\n",
    "                        sigmoid(np.matmul(v_hat,x_bar_hat_last))))*Ts + x_hat_last\n",
    "\n",
    "        x_bar_hat = np.concatenate((x_hat,u[:,i].reshape(-1,1)),axis=0)\n",
    "        x_bar_hat_last = x_bar_hat\n",
    "        w_hat_last = w_hat\n",
    "        v_hat_last = v_hat\n",
    "    return (w_hat,v_hat,x_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model(w, v, x, activation = 'sig'):\n",
    "    first_layer = np.matmul(v,x)\n",
    "    if activation == 'sig':\n",
    "        first_layer = sigmoid(first_layer)\n",
    "    output = np.matmul(w,first_layer)\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6974e7273c73db9ae5330bea447196dc7d348414c6c6b926fa6b7ad39c9ef33b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
